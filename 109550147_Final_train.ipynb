{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "#read csv file\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "sample = pd.read_csv(\"sample_submission.csv\")\n",
    "cat_all = train_data.columns[2:25].tolist() #get out the feature name\n",
    "val_ind = train_data.columns[25:26].tolist() #get out the target name\n",
    "\n",
    "rep = {'material_5':5, 'material_6':6, 'material_7':7, 'material_8':8} #how to replace the material with number\n",
    "#replace two columns in train_data and test_data\n",
    "train_data = train_data.replace({'attribute_0': rep})\n",
    "train_data = train_data.replace({'attribute_1': rep})\n",
    "test_data = test_data.replace({'attribute_0': rep})\n",
    "test_data = test_data.replace({'attribute_1': rep})\n",
    "\n",
    "#fill in the nan value\n",
    "#inspire by https://www.kaggle.com/code/tomjosephmo/logistic-regression-with-missing-values-accounted\n",
    "for col in train_data.columns: #modify train data\n",
    "    if not type(train_data[col][0]) == str: #if it is nan\n",
    "        train_data[col].fillna(train_data[col].mean(), inplace=True)\n",
    "        \n",
    "for col in test_data.columns: #modify test data\n",
    "    if not type(test_data[col][0]) == str: #if it is nan\n",
    "        test_data[col].fillna(test_data[col].mean(), inplace=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #if cuda is available use cuda\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "x_train = train_data[cat_all].values #get out the feature training data\n",
    "y_train = train_data[val_ind].values #get out the target training data\n",
    "y_train = y_train.flatten()\n",
    "x_test = test_data[cat_all].values #get out the feature test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPS_train_dataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "        self.y_data = torch.tensor(y_data, dtype=torch.float32)\n",
    "        self.length = self.x_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        return self.x_data[ind], self.y_data[ind] #return x data and y data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "class TPS_test_dataset(Dataset):\n",
    "    def __init__(self, x_data):\n",
    "        self.x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "        self.length = self.x_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        return self.x_data[ind] #test data dont have target feature so only return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#three fully connected layer\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_feature):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_feature, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 1) #make output of the network to right dimension\n",
    "\n",
    "    def forward(self, x_data):\n",
    "        x_data = torch.relu(self.fc1(x_data)) #put in relu activation function\n",
    "        x_data = torch.relu(self.fc2(x_data))\n",
    "        x_data = torch.sigmoid(self.fc3(x_data)) #use sigmoid to make value between 0-1\n",
    "        return x_data #return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Epoch:  10\n",
      "Epoch:  11\n",
      "Epoch:  12\n",
      "Epoch:  13\n",
      "Epoch:  14\n",
      "Epoch:  15\n",
      "Epoch:  16\n",
      "Epoch:  17\n",
      "Epoch:  18\n",
      "Epoch:  19\n",
      "Epoch:  20\n",
      "Epoch:  21\n",
      "Epoch:  22\n",
      "Epoch:  23\n",
      "Epoch:  24\n",
      "Epoch:  25\n",
      "Epoch:  26\n",
      "Epoch:  27\n",
      "Epoch:  28\n",
      "Epoch:  29\n",
      "Epoch:  30\n",
      "Epoch:  31\n",
      "Epoch:  32\n",
      "Epoch:  33\n",
      "Epoch:  34\n",
      "Epoch:  35\n",
      "Epoch:  36\n",
      "Epoch:  37\n",
      "Epoch:  38\n",
      "Epoch:  39\n",
      "Epoch:  40\n",
      "Epoch:  41\n",
      "Epoch:  42\n",
      "Epoch:  43\n",
      "Epoch:  44\n",
      "Epoch:  45\n",
      "Epoch:  46\n",
      "Epoch:  47\n",
      "Epoch:  48\n",
      "Epoch:  49\n",
      "Epoch:  50\n",
      "Epoch:  51\n",
      "Epoch:  52\n",
      "Epoch:  53\n",
      "Epoch:  54\n",
      "Epoch:  55\n",
      "Epoch:  56\n",
      "Epoch:  57\n",
      "Epoch:  58\n",
      "Epoch:  59\n",
      "Epoch:  60\n",
      "Epoch:  61\n",
      "Epoch:  62\n",
      "Epoch:  63\n",
      "Epoch:  64\n",
      "Epoch:  65\n",
      "Epoch:  66\n",
      "Epoch:  67\n",
      "Epoch:  68\n",
      "Epoch:  69\n",
      "Epoch:  70\n",
      "Epoch:  71\n",
      "Epoch:  72\n",
      "Epoch:  73\n",
      "Epoch:  74\n",
      "Epoch:  75\n",
      "Epoch:  76\n",
      "Epoch:  77\n",
      "Epoch:  78\n",
      "Epoch:  79\n",
      "Epoch:  80\n",
      "Epoch:  81\n",
      "Epoch:  82\n",
      "Epoch:  83\n"
     ]
    }
   ],
   "source": [
    "#load training data\n",
    "train_ds = TPS_train_dataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size = 16, shuffle = True) #need to shuffle\n",
    "#load test data\n",
    "test_ds = TPS_test_dataset(x_test)\n",
    "test_dl = DataLoader(test_ds, batch_size = 1, shuffle = False)\n",
    "\n",
    "#initialize the model, optimizer and loss function\n",
    "#learning rate of optimizer is 1e-3\n",
    "model = Model(num_feature = x_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fn = nn.BCELoss() #Use binary cross entropy\n",
    "losses = []\n",
    "for i in range(200): #run 200 epochs\n",
    "    print(\"Epoch: \", i)\n",
    "    for x, y in train_dl:\n",
    "        output = model(x)\n",
    "        loss = loss_fn(output, y.reshape(-1, 1)) #calculate the loss\n",
    "        #updata\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.array([i for i in range(26570, 47345)])\n",
    "result = []\n",
    "model.eval() #turn model to evalution mode\n",
    "torch.save(model.state_dict(), \"model.pt\")\n",
    "for x_data in test_dl:\n",
    "    pred = model(x_data) #predict the result\n",
    "    pred = pred.detach().numpy()\n",
    "    pred = pred.flatten()\n",
    "    result = np.concatenate((result, pred)) #concate all result together\n",
    "\n",
    "df = pd.DataFrame({\"id\":ind, \"failure\":result}, columns = [\"id\", \"failure\"]) #set dataframe\n",
    "df.to_csv(f\"109550147_submission.csv\", index=False) #index set to false so that csv file dont have one extra column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
